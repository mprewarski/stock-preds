{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4846f067-86fb-4f32-8d54-b28617cd2cf7",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a1fc5f-c8ae-48fa-9d3f-b380f1fc78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "from itertools import cycle\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec934625-61d3-4349-9517-88f1976429e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for now since these models are so small they run well on CPU\n",
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available()  else 'cpu')\n",
    "#device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839fbf93-7a52-47cb-92e6-047c271be1c9",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd3039e-cce9-4b38-92af-45b905745b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'Date': 'date','Open':'open','High':'high','Low':'low',\n",
    "                            'Close':'close','Adj Close':'adj_close','Volume':'volume'})\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac9dc3c5-69ac-4300-807e-00113a2e2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame):\n",
    "    if df.isnull().values.sum() > 0:\n",
    "        print(\"Uh oh, null values\")\n",
    "        print(df.isnull().values.sum())\n",
    "    if df.isna().values.any():\n",
    "        print(\"NA values\")\n",
    "\n",
    "    # convert date field from string to Date format\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257bc5df-c4bc-4328-8d40-b7ed5387e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_open_close_prices(df:pd.DataFrame):\n",
    "    fig = px.line(maindf,\n",
    "              x=maindf['date'], \n",
    "              y=[maindf['open'],\n",
    "                maindf['close']],        \n",
    "              labels={'value':'Stock price','date': 'Date'})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "826b07a7-445d-4d99-90f5-c7ed6ddfee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame):\n",
    "    closedf = np.array(maindf['close']).reshape(-1,1)\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    closedf=scaler.fit_transform(np.array(closedf).reshape(-1,1))\n",
    "    return closedf, scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aae30a5-6749-4f77-988d-195d471978d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maindf = pd.read_csv(\"data/NVDA.csv\")\n",
    "#maindf = pd.read_csv(\"data/TSLA.csv\")\n",
    "maindf = import_data(\"data/AAPL.csv\")\n",
    "maindf = preprocess_data(maindf)\n",
    "#plot_open_close_prices(maindf)\n",
    "closedf, scaler = prepare_data(maindf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f3b60-02ee-4c02-9c76-dfec3728c07c",
   "metadata": {},
   "source": [
    "# Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b18d1-8d32-49f7-8d7c-dc505e847e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef4f64-719a-499e-81b2-012844a5d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 15 # the number of data steps used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ffc67b-48da-4dc4-b375-6a6415daac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_used = len(closedf)\n",
    "training_size=int(steps_used*0.65)\n",
    "test_size= steps_used-training_size \n",
    "train_data,test_data=closedf[0:training_size,:],closedf[training_size:steps_used,:1]\n",
    "print(\"train_data: \", train_data.shape)\n",
    "print(\"test_data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e28ce-3494-428c-9768-937d60a39a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42ef74-eeb2-42e4-896e-2f997a0bbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ce2a4-3280-406a-a043-78bdf31ff308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045febe-258e-48b7-8a63-79457c6bd187",
   "metadata": {},
   "source": [
    "Convert the data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b7476-190f-4f7e-88f9-616e263085b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).type(torch.Tensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor).unsqueeze(dim = 1)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor).unsqueeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c9cd8-847a-424b-850b-311406d08638",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train.shape = ',X_train.shape)\n",
    "print('y_train.shape = ',y_train.shape)\n",
    "print('x_test.shape = ',X_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdabb1e-8e83-4f68-b52c-230b48960927",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ccddbe-76a8-4cea-b34b-506d65090c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 32, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904dfbc0-1b92-4839-9089-7ee28ac53693",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294d0ba-f697-4cf8-a44d-3b9dcf9a56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2 \n",
    "output_dim = 1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "print(model.parameters())\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print \n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a36326-80e1-43f4-8412-d11495a926b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecb6d7-73ac-46d1-bea1-06fc11009dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "num_epochs = 300\n",
    "hist = { \n",
    "    \"loss\" : np.zeros(num_epochs),\n",
    "    \"val_loss\" : np.zeros(num_epochs)\n",
    "}\n",
    "best_val_loss = float('inf')\n",
    "BEST_MODEL_PATH = \"best_model.mod\"\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_train_pred = model(X_train)\n",
    "\n",
    "    loss = loss_fn(y_train_pred, y_train)\n",
    "    hist[\"loss\"][t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters\n",
    "    optimiser.step()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    y_test_pred = model(X_test)\n",
    "    val_loss = loss_fn(y_test_pred, y_test)\n",
    "    hist[\"val_loss\"][t] = val_loss.item()\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        #print(f\"saving model at {t}, loss {val_loss}\")\n",
    "        torch.save({\n",
    "            'epoch': t,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimiser.state_dict(),\n",
    "            'loss': val_loss\n",
    "            }, BEST_MODEL_PATH)\n",
    "    model.train()\n",
    "\n",
    "    if t % 10 == 0 and t !=0:\n",
    "        #print(\"Epoch \", t, \"train MSE: \", loss.item())\n",
    "        print(f\"Epoch {t}  train MSE {loss.item():2.5f}  val MSE {val_loss.item():2.5f}\")\n",
    "\n",
    "print(f\"Epoch {t}  train MSE {loss.item():2.5f}  val MSE {val_loss.item():2.5f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db9417-0166-4aec-b3dd-595df738ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(num_epochs)\n",
    "plt.plot(epochs, hist[\"loss\"], 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, hist[\"val_loss\"], 'b', label=\"Validation loss\")\n",
    "plt.title(\"training and validation loss\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7e444-2ecd-4426-a6af-70d796acbe1c",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7496383-1ad0-470f-a449-72e9146c776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(BEST_MODEL_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimiser.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "print(f\"Best model loaded from epoch {epoch}, loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1fa0d5-403b-453e-8f0f-8bae513cab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12b501-a598-4832-9db6-e6612c296f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model(X_train)\n",
    "test_predict=model(X_test)\n",
    "train_predict.shape, test_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71504614-83cb-4ac5-afa0-0ef2432e6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = scaler.inverse_transform(train_predict.detach().numpy())\n",
    "test_predict = scaler.inverse_transform(test_predict.detach().numpy())\n",
    "original_ytrain = scaler.inverse_transform(y_train.detach().numpy()) \n",
    "original_ytest = scaler.inverse_transform(y_test.detach().numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32993cc-d03a-4ee5-83e2-f06a0c419083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrices RMSE and MAE\n",
    "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_ytrain,train_predict)))\n",
    "print(\"Train data MSE: \", mean_squared_error(original_ytrain,train_predict))\n",
    "print(\"Train data MAE: \", mean_absolute_error(original_ytrain,train_predict))\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_ytest,test_predict)))\n",
    "print(\"Test data MSE: \", mean_squared_error(original_ytest,test_predict))\n",
    "print(\"Test data MAE: \", mean_absolute_error(original_ytest,test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e869f1-cb0d-47eb-b674-c6c76c82f1a4",
   "metadata": {},
   "source": [
    "### Explained variance regression score\n",
    "The explained variance score explains the dispersion of errors of a given dataset, and the formula is written as follows: Here, and Var(y) is the variance of prediction errors and actual values respectively. Scores close to 1.0 are highly desired, indicating better squares of standard deviations of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6168d0-d59b-406e-9f21-4e0c48fad42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data explained variance regression score:\", explained_variance_score(original_ytrain, train_predict))\n",
    "print(\"Test data explained variance regression score:\", explained_variance_score(original_ytest, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63245c69-175b-4bec-8684-1b31b598b099",
   "metadata": {},
   "source": [
    "<a name=\"r2\"></a>\n",
    "\n",
    "### R<sup>2</sup> score for regression\n",
    "\n",
    "R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.\n",
    "\n",
    "1 = Best <br>\n",
    "0 or < 0 = worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a59ab9-32a5-482b-9a2e-c642d4cc3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data R2 score:\", r2_score(original_ytrain, train_predict))\n",
    "print(\"Test data R2 score:\", r2_score(original_ytest, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccee83e-dc2b-4773-a3f8-eae0703adf90",
   "metadata": {},
   "source": [
    "<a name=\"cp\"></a>\n",
    "\n",
    "# Comparision of original stock close price and predicted close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87149c23-3604-46e0-bc59-7949b4487176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "\n",
    "look_back=time_step\n",
    "trainPredictPlot = np.empty_like(closedf)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "print(\"Train predicted data: \", trainPredictPlot.shape)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(closedf)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(closedf)-1, :] = test_predict\n",
    "print(\"Test predicted data: \", testPredictPlot.shape)\n",
    "\n",
    "names = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n",
    "\n",
    "\n",
    "plotdf = pd.DataFrame({'date': maindf['date'],\n",
    "                       'original_close': maindf['close'],\n",
    "                      'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n",
    "                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n",
    "\n",
    "fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n",
    "                                          plotdf['test_predicted_close']],\n",
    "              labels={'value':'Stock price','date': 'Date'})\n",
    "fig.update_layout(title_text='Comparision between original close price vs predicted close price',\n",
    "                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n",
    "fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
    "\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.update_yaxes(showgrid=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429a5ad-3231-4da1-b689-4f3361fec667",
   "metadata": {},
   "source": [
    "## Predicting next 20 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a078fe0-67a2-4b34-a509-8d988a902730",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_days = 20\n",
    "# store last 15 test samples in a list\n",
    "x_input_list = list(test_data[-time_step:].squeeze())\n",
    "preds = np.zeros(pred_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c911d-fc4e-4b40-b682-3db13db89c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pred_days):\n",
    "    # convert the input list to a tensor of the correct dimensions\n",
    "    x_input = torch.FloatTensor(x_input_list).unsqueeze(dim=0).unsqueeze(dim=2)\n",
    "    # make a prediction\n",
    "    yhat = model(x_input)\n",
    "    # convert the tensor back to float\n",
    "    yhat_float = float(yhat.detach().numpy()[0][0])\n",
    "    preds[i] = yhat_float\n",
    "    # remove the first element of the list and add the prediction\n",
    "    x_input_list = x_input_list[1:]\n",
    "    x_input_list.append(yhat_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178f9a1-6407-4813-b6dd-b7973f9118c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb6a9e-39be-4f56-8e5a-01760077db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_data[-time_step:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb7970-6a91-47e8-b9a6-2d13fe353b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_next_20 = scaler.inverse_transform(preds.reshape(1,-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d4a9c-386f-4874-ab82-f8ec546a6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(preds_next_20.squeeze(), columns = [\"preds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f129461-4d6b-4f79-80a9-0644a4d19772",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df, y = \"preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da0e88-a554-4764-b813-0495b2ee7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a27e6a-2d25-4aa1-a4a1-ffd97b4fc69d",
   "metadata": {},
   "source": [
    "## Displaying all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565e3c5-af5d-4dd2-a14e-a2f5c8b03723",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredictPlot = np.zeros((fulldf.shape[0]))\n",
    "testPredictPlot = np.zeros((fulldf.shape[0]))\n",
    "next20PredictPlot = np.zeros((fulldf.shape[0]))\n",
    "trainPredictPlot[:] = np.nan\n",
    "testPredictPlot[:] = np.nan\n",
    "next20PredictPlot[:] = np.nan\n",
    "\n",
    "start_train = time_step\n",
    "end_train = start_train + train_predict.shape[0]\n",
    "\n",
    "start_test = end_train + time_step\n",
    "end_test = start_test + test_predict.shape[0]\n",
    "\n",
    "start_next = end_test\n",
    "end_next = start_next + preds_next_20.shape[1]\n",
    "\n",
    "trainPredictPlot[start_train : end_train] = train_predict.squeeze()\n",
    "testPredictPlot[start_test : end_test] = test_predict.squeeze()\n",
    "next20PredictPlot[start_next : end_next] = preds_next_20[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea65ab-8dda-416c-ac90-c4d697cdf171",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = pd.DataFrame({'date': fulldf['date'],\n",
    "                       'original_close': fulldf['close'],\n",
    "                      'train_predicted_close': trainPredictPlot.tolist(),\n",
    "                      'test_predicted_close': testPredictPlot.tolist(),\n",
    "                      'next_20_predicted_close': next20PredictPlot.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a668a-05c2-47c4-bcfc-bc3645ba4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],\n",
    "                                          plotdf['train_predicted_close'],\n",
    "                                          plotdf['test_predicted_close'],\n",
    "                                          plotdf['next_20_predicted_close']\n",
    "                                         ],\n",
    "                                         \n",
    "              labels={'value':'Stock price','date': 'Date'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda6bcc-0912-4d0f-947e-2b6c69cf9cd5",
   "metadata": {},
   "source": [
    "# Additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d7891-1e0f-4dc2-b8c7-fe5890fadb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test = original_ytest.squeeze()\n",
    "pred_test = test_predict.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77a885-cb7b-48b9-b421-70b0561bfb8c",
   "metadata": {},
   "source": [
    "## holding through the test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408b6c6-4d15-4e66-8aef-4a2424baa7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_value = (orig_test[-1] - orig_test[0])\n",
    "hold_change = hold_value / orig_test[0]\n",
    "hold_value, hold_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b0338-8b9d-44aa-b591-859d62934a07",
   "metadata": {},
   "source": [
    "## long only on predicted up days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81dcc5-eed3-451e-a456-4ec101765d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 0\n",
    "for i in range(len(pred_test)):\n",
    "    if i == 0: continue\n",
    "    if pred_test[i] > pred_test[i-1]:\n",
    "        value += orig_test[i] - orig_test[i-1]\n",
    "value, value / orig_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a722f-3078-48df-9085-3c2559065935",
   "metadata": {},
   "source": [
    "## short only on predicted down days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3666b4-c70f-4561-9284-018b6cbddd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 0\n",
    "for i in range(len(pred_test)):\n",
    "    if i == 0: continue\n",
    "    if pred_test[i] < pred_test[i-1]:\n",
    "        value -= orig_test[i] - orig_test[i-1]\n",
    "value, value / orig_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b0933-862b-4609-980a-41da3e238d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

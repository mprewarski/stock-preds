{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcd69e-6bcd-4417-8daf-e5ae3995cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4d2cc-77f2-49dc-8dfc-f8557cc51c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available()  else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839fbf93-7a52-47cb-92e6-047c271be1c9",
   "metadata": {},
   "source": [
    "# Import Dataset\n",
    "Examine the data a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59841c5-b4b4-457a-be9e-e701f47e08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_data = pd.read_csv(\"./NVDA.csv\", index_col=\"Date\")\n",
    "maindf = pd.read_csv(\"./TSLA.csv\")\n",
    "maindf = maindf.rename(columns={'Date': 'date','Open':'open','High':'high','Low':'low','Close':'close',\n",
    "                                'Adj Close':'adj_close','Volume':'volume'})\n",
    "maindf.shape, maindf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48900b0b-1778-40b3-af5e-53acb1b2bb34",
   "metadata": {},
   "source": [
    "Check for any null or empty values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed12a9-930b-4efb-be23-f0768c5b4c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null values:\", maindf.isnull().values.sum())\n",
    "print(\"NA values:\", maindf.isna().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65bcbf3-2aea-4f91-803d-a98b8498aa78",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96b874-f452-4eab-b28a-dafd88be8aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date field from string to Date format \n",
    "print(maindf['date'].head)\n",
    "maindf['date'] = pd.to_datetime(maindf.date)\n",
    "maindf['date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff85c0-a2ce-4b66-8afd-656c441fc85a",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c20c30-311a-4c54-8b1e-2ecc8ca85a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting date: \",maindf.iloc[0][0])\n",
    "print(\"Ending date: \", maindf.iloc[-1][0])\n",
    "print(\"Duration: \", maindf.iloc[-1][0]-maindf.iloc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f0fff-2612-4b4f-bd4f-8adc176d45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=30))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.plot(maindf['date'], maindf['close'], label=\"Close\")\n",
    "plt.plot(maindf['date'], maindf['open'], label=\"Open\")\n",
    "plt.xlabel(\"Time Scale\")\n",
    "plt.ylabel(\"USD\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215bc28d-acd3-41b8-a692-c0bbcd560d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a8c6a-fb03-4c4d-8aaf-4506fb5d767d",
   "metadata": {},
   "source": [
    "# Preparing Closing Price - target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b0864f-95a8-4e3c-906a-44974bef22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "closedf = maindf[['date','close']]\n",
    "print(\"Shape of close dataframe:\", closedf.shape)\n",
    "closedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36d1b5-caf8-4a7e-b22f-67dd9aba9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0f1ec-ebe5-484e-b167-f5c188e90600",
   "metadata": {},
   "outputs": [],
   "source": [
    "del closedf['date']\n",
    "closedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b002d-b4d2-44e9-934b-68579e146e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "closedf=scaler.fit_transform(np.array(closedf).reshape(-1,1))\n",
    "print(closedf.shape)\n",
    "closedf[:5], closedf.min(), closedf.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f3b60-02ee-4c02-9c76-dfec3728c07c",
   "metadata": {},
   "source": [
    "#Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ffc67b-48da-4dc4-b375-6a6415daac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size=int(len(closedf)*0.60)\n",
    "test_size=len(closedf)-training_size\n",
    "train_data,test_data=closedf[0:training_size,:],closedf[training_size:len(closedf),:1]\n",
    "print(\"train_data: \", train_data.shape)\n",
    "print(\"test_data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e28ce-3494-428c-9768-937d60a39a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42ef74-eeb2-42e4-896e-2f997a0bbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ce2a4-3280-406a-a043-78bdf31ff308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045febe-258e-48b7-8a63-79457c6bd187",
   "metadata": {},
   "source": [
    "Convert the data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b7476-190f-4f7e-88f9-616e263085b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).type(torch.Tensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "y_train.unsqueeze_(dim=1)\n",
    "y_test.unsqueeze_(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c9cd8-847a-424b-850b-311406d08638",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train.shape = ',X_train.shape)\n",
    "print('y_train.shape = ',y_train.shape)\n",
    "print('x_test.shape = ',X_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdabb1e-8e83-4f68-b52c-230b48960927",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce25693-c045-47b9-8b5c-eb19f2bd0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ccddbe-76a8-4cea-b34b-506d65090c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 32, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294d0ba-f697-4cf8-a44d-3b9dcf9a56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2 \n",
    "output_dim = 1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "print(model.parameters())\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print \n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecb6d7-73ac-46d1-bea1-06fc11009dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "num_epochs = 95\n",
    "hist = { \n",
    "    \"loss\" : np.zeros(num_epochs),\n",
    "    \"val_loss\" : np.zeros(num_epochs)\n",
    "}\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_train_pred = model(X_train)\n",
    "\n",
    "    loss = loss_fn(y_train_pred, y_train)\n",
    "    hist[\"loss\"][t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters\n",
    "    optimiser.step()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    y_test_pred = model(X_test)\n",
    "    val_loss = loss_fn(y_test_pred, y_test)\n",
    "    hist[\"val_loss\"][t] = val_loss.item()\n",
    "    model.train()\n",
    "\n",
    "    if t % 10 == 0 and t !=0:\n",
    "        #print(\"Epoch \", t, \"train MSE: \", loss.item())\n",
    "        print(f\"Epoch {t}  train MSE {loss.item():2.5f}  val MSE {val_loss.item():2.5f}\")\n",
    "\n",
    "print(f\"Epoch {t}  train MSE {loss.item():2.5f}  val MSE {val_loss.item():2.5f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db9417-0166-4aec-b3dd-595df738ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(num_epochs)\n",
    "plt.plot(epochs, hist[\"loss\"], 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, hist[\"val_loss\"], 'b', label=\"Validation loss\")\n",
    "plt.title(\"training and validation loss\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7e444-2ecd-4426-a6af-70d796acbe1c",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12b501-a598-4832-9db6-e6612c296f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model(X_train)\n",
    "test_predict=model(X_test)\n",
    "train_predict.shape, test_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71504614-83cb-4ac5-afa0-0ef2432e6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = scaler.inverse_transform(train_predict.detach().numpy())\n",
    "test_predict = scaler.inverse_transform(test_predict.detach().numpy())\n",
    "original_ytrain = scaler.inverse_transform(y_train.detach().numpy()) \n",
    "original_ytest = scaler.inverse_transform(y_test.detach().numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57c231-5535-4077-8f39-fa2a2221058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32993cc-d03a-4ee5-83e2-f06a0c419083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrices RMSE and MAE\n",
    "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_ytrain,train_predict)))\n",
    "print(\"Train data MSE: \", mean_squared_error(original_ytrain,train_predict))\n",
    "print(\"Train data MAE: \", mean_absolute_error(original_ytrain,train_predict))\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_ytest,test_predict)))\n",
    "print(\"Test data MSE: \", mean_squared_error(original_ytest,test_predict))\n",
    "print(\"Test data MAE: \", mean_absolute_error(original_ytest,test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e869f1-cb0d-47eb-b674-c6c76c82f1a4",
   "metadata": {},
   "source": [
    "### Explained variance regression score\n",
    "The explained variance score explains the dispersion of errors of a given dataset, and the formula is written as follows: Here, and Var(y) is the variance of prediction errors and actual values respectively. Scores close to 1.0 are highly desired, indicating better squares of standard deviations of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6168d0-d59b-406e-9f21-4e0c48fad42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data explained variance regression score:\", explained_variance_score(original_ytrain, train_predict))\n",
    "print(\"Test data explained variance regression score:\", explained_variance_score(original_ytest, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63245c69-175b-4bec-8684-1b31b598b099",
   "metadata": {},
   "source": [
    "<a name=\"r2\"></a>\n",
    "\n",
    "### R<sup>2</sup> score for regression\n",
    "\n",
    "R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.\n",
    "\n",
    "1 = Best <br>\n",
    "0 or < 0 = worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a59ab9-32a5-482b-9a2e-c642d4cc3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data R2 score:\", r2_score(original_ytrain, train_predict))\n",
    "print(\"Test data R2 score:\", r2_score(original_ytest, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccee83e-dc2b-4773-a3f8-eae0703adf90",
   "metadata": {},
   "source": [
    "<a name=\"cp\"></a>\n",
    "\n",
    "# Comparision of original stock close price and predicted close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b164a80-975c-4f7a-91ef-2ca51368f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3a560-3836-405d-bb69-3c1f57a838a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87149c23-3604-46e0-bc59-7949b4487176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "\n",
    "look_back=time_step\n",
    "trainPredictPlot = np.empty_like(closedf)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "print(\"Train predicted data: \", trainPredictPlot.shape)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(closedf)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(closedf)-1, :] = test_predict\n",
    "print(\"Test predicted data: \", testPredictPlot.shape)\n",
    "\n",
    "names = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n",
    "\n",
    "\n",
    "plotdf = pd.DataFrame({'date': maindf['date'],\n",
    "                       'original_close': maindf['close'],\n",
    "                      'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n",
    "                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n",
    "\n",
    "fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n",
    "                                          plotdf['test_predicted_close']],\n",
    "              labels={'value':'Stock price','date': 'Date'})\n",
    "fig.update_layout(title_text='Comparision between original close price vs predicted close price',\n",
    "                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n",
    "fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
    "\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.update_yaxes(showgrid=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed3fd6-0837-4725-81b5-a68c60459775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
